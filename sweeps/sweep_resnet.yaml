method: random
metric:
  goal: maximize
  name: val_accuracy

parameters:
  dataset.train_path:
    value: ../../MIT_small_train_1/train
  dataset.val_path:
    value: ../../MIT_small_train_1/test
  dataset.input_shape:
    value: 224
  dataset.batch_size:
    value: 16
  dataset.augment:
    value: True
  dataset.preprocessing_function:
    values:
      - tf.keras.applications.resnet50.preprocess_input
      - preprocess_input

  teacher_model.model_path:
    value: ../w4/models/base_model.h5
  teacher_model.weights_path:
    value: ../w4/weights/base_model.h5
  teacher_model.save_model_path_student:
    value: models/student.h5
  teacher_model.temperature:
    values:
      - 0.5
      - 0.6
      - 0.7
      - 0.8
      - 0.9
      - 1.0
      - 1.1
      - 1.2
      - 1.3
      - 1.4
      - 1.5
      - 1.6
      - 1.7
      - 1.8
      - 1.9
      - 2.0
  teacher_model.alpha:
    values:
      - 0.1
      - 0.2
      - 0.3
      - 0.4
      - 0.5
      - 0.6
      - 0.7
      - 0.8
      - 0.9


  optimizer.name:
    value: Adam
  optimizer.settings.learning_rate:
    values:
      - 0.01
      - 0.001
  optimizer.settings.decay:
    values:
      - 0.01
      - 0.001
  optimizer.warmup_steps:
    values:
      - 30
      - 40
  optimizer.cosine_decay:
    values:
      - 0.5
      - 0.9



  model.name:
    value: resnet50
  model.last_layer:
    value: "conv3_block4_out" # outputs = ['pool1_pool','conv2_block3_out', 'conv3_block4_out', 'conv4_block6_out', 'conv5_block3_out']
  model.dropout:
    value: 0
  model.n_classes:
    value: 8
  model.weights:
    value: imagenet #None if trained from scratch


  loss:
    value: categorical_crossentropy

  n_epochs:
    value: 65
